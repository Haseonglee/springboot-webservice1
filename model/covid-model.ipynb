{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2959.231514,
      "end_time": "2021-06-03T07:07:54.892900",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-06-03T06:18:35.661386",
      "version": "2.3.3"
    },
    "colab": {
      "name": "notebook8f7ef5641f.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haseonglee/springboot-webservice1/blob/master/model/covid-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QKa08KPZYRe",
        "outputId": "69c90502-3b28-4ce1-8a34-ee6aa7cc6d89"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "3QKa08KPZYRe",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2021-06-03T06:18:43.835136Z",
          "iopub.status.busy": "2021-06-03T06:18:43.833059Z",
          "iopub.status.idle": "2021-06-03T06:20:38.568050Z",
          "shell.execute_reply": "2021-06-03T06:20:38.567318Z",
          "shell.execute_reply.started": "2021-06-03T06:02:15.765037Z"
        },
        "papermill": {
          "duration": 114.754304,
          "end_time": "2021-06-03T06:20:38.568236",
          "exception": false,
          "start_time": "2021-06-03T06:18:43.813932",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sublime-batch",
        "outputId": "7a41fc93-3a6d-47e8-b2ab-685a75df0701"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob, sys, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "img_dir = '/content/drive/MyDrive/Covid Model/CT'\n",
        "categories = ['COVID','Non-COVID']\n",
        "n_classes = len(categories)\n",
        "\n",
        "image_w = 112\n",
        "image_h = 112\n",
        "\n",
        "\n",
        "pixel = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    img_dir_detail = img_dir + \"/\" + cat\n",
        "    files = glob.glob(img_dir_detail+\"/*.png\")\n",
        "\n",
        "\n",
        "    for i, f in enumerate(files):\n",
        "        try:\n",
        "            img = Image.open(f)\n",
        "            img = img.convert(\"RGB\")\n",
        "            img = img.resize((image_w, image_h))\n",
        "            data = np.asarray(img)\n",
        "            #Y는 0 아니면 1이니까 idx값으로 넣는다.\n",
        "            X.append(data)\n",
        "            y.append(idx)\n",
        "            if i % 300 == 0:\n",
        "                print(cat, \" : \", f)\n",
        "        except:\n",
        "            print(cat, str(i)+\" 번째에서 에러 \")\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"/content/drive/MyDrive/Covid Model/binary_image_data.npy\", xy)"
      ],
      "id": "sublime-batch",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/radiopaedia_org_covid-19-pneumonia-10_85902_3-dcm_z139.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/radiopaedia_org_covid-19-pneumonia-14_85914_0-dcm_z003.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/radiopaedia_org_covid-19-pneumonia-40_86625_0-dcm_z013.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/tr_mask_z016.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_008_z226.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_009_z216.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_010_z294.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_004_z170.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_005_z161.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_006_z193.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/Covid (835).png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_001_z084.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_002_z044.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/coronacases_org_003_z146.png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/Covid (1202).png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/Covid (386).png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/Covid (631).png\n",
            "COVID  :  /content/drive/MyDrive/Covid Model/CT/COVID/2020.02.25.20021568-p24-111%8.png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/Non-Covid (1182).png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/Non-Covid (368).png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/Non-Covid (63).png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/Non-Covid (886).png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/1.3.6.1.4.1.14519.5.2.1.6279.6001.513023675145166449943177283490.mhd_87.png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/25.png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/1.3.6.1.4.1.14519.5.2.1.6279.6001.104562737760173137525888934217.mhd_196.png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/1.3.6.1.4.1.14519.5.2.1.6279.6001.188376349804761988217597754952.mhd_109.png\n",
            "Non-COVID  :  /content/drive/MyDrive/Covid Model/CT/Non-COVID/1.3.6.1.4.1.14519.5.2.1.6279.6001.293593766328917170359373773080.mhd_182.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:38.618039Z",
          "iopub.status.busy": "2021-06-03T06:20:38.616872Z",
          "iopub.status.idle": "2021-06-03T06:20:38.991361Z",
          "shell.execute_reply": "2021-06-03T06:20:38.992214Z",
          "shell.execute_reply.started": "2021-06-03T06:05:16.02403Z"
        },
        "papermill": {
          "duration": 0.403139,
          "end_time": "2021-06-03T06:20:38.992481",
          "exception": false,
          "start_time": "2021-06-03T06:20:38.589342",
          "status": "completed"
        },
        "tags": [],
        "id": "secret-patient",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9784c8d1-3dfe-4fe7-eea3-65df2e3abb04"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#np_load_old = np.load\n",
        "#np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
        "X_train, X_test, y_train, y_test = np.load('/content/drive/MyDrive/Covid Model/binary_image_data.npy', allow_pickle=True)\n",
        "#np.load = np_load_old\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[0])\n",
        "print(np.bincount(y_train))\n",
        "print(np.bincount(y_test))"
      ],
      "id": "secret-patient",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6993, 112, 112, 3)\n",
            "6993\n",
            "[4841 2152]\n",
            "[505 272]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:39.043675Z",
          "iopub.status.busy": "2021-06-03T06:20:39.042364Z",
          "iopub.status.idle": "2021-06-03T06:20:39.976071Z",
          "shell.execute_reply": "2021-06-03T06:20:39.975483Z",
          "shell.execute_reply.started": "2021-06-03T06:05:19.915793Z"
        },
        "papermill": {
          "duration": 0.961774,
          "end_time": "2021-06-03T06:20:39.976239",
          "exception": false,
          "start_time": "2021-06-03T06:20:39.014465",
          "status": "completed"
        },
        "tags": [],
        "id": "sunset-vintage",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2af08fd-5505-4e69-eea2-6b5bb2f88459"
      },
      "source": [
        "IMAGE_SIZE = 112\n",
        "BATCH_SIZE = 16\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, X_val.shape, y_val.shape)"
      ],
      "id": "sunset-vintage",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6993, 112, 112, 3) (6993, 2) (777, 112, 112, 3) (777, 2)\n",
            "(5594, 112, 112, 3) (5594, 2) (777, 112, 112, 3) (777, 2) (1399, 112, 112, 3) (1399, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:40.036167Z",
          "iopub.status.busy": "2021-06-03T06:20:40.030459Z",
          "iopub.status.idle": "2021-06-03T06:20:40.218448Z",
          "shell.execute_reply": "2021-06-03T06:20:40.217850Z",
          "shell.execute_reply.started": "2021-06-03T06:05:23.146486Z"
        },
        "papermill": {
          "duration": 0.219789,
          "end_time": "2021-06-03T06:20:40.218647",
          "exception": false,
          "start_time": "2021-06-03T06:20:39.998858",
          "status": "completed"
        },
        "tags": [],
        "id": "bridal-joseph"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import cv2\n",
        "import sklearn\n",
        "\n",
        "# 입력 인자 images_array labels는 모두 numpy array로 들어옴. \n",
        "# 인자로 입력되는 images_array는 전체 32x32 image array임. \n",
        "class _Dataset(Sequence):\n",
        "    def __init__(self, images_array, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        images_array: 원본 32x32 만큼의 image 배열값. \n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        # 인자로 입력되는 images_array는 전체 32x32 image array임.\n",
        "        self.images_array = images_array\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
        "    def __getitem__(self, index):\n",
        "        images_fetch = self.images_array[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # 변환된 image 배열값을 담을 image_batch 선언. image_batch 배열은 float32 로 설정. \n",
        "        image_batch = np.zeros((images_fetch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
        "        for image_index in range(images_fetch.shape[0]):\n",
        "            #image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            # 원본 image를 IMAGE_SIZE x IMAGE_SIZE 크기로 변환\n",
        "            image = cv2.resize(images_fetch[image_index], (IMAGE_SIZE, IMAGE_SIZE))\n",
        "            # 만약 augmentor가 주어졌다면 이를 적용. \n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "                \n",
        "            # 만약 scaling 함수가 입력되었다면 이를 적용하여 scaling 수행. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "            \n",
        "            # image_batch에 순차적으로 변환된 image를 담음.               \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 원본 image배열과 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.images_array, self.labels = sklearn.utils.shuffle(self.images_array, self.labels)\n",
        "        else:\n",
        "            pass"
      ],
      "id": "bridal-joseph",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:40.267692Z",
          "iopub.status.busy": "2021-06-03T06:20:40.267005Z",
          "iopub.status.idle": "2021-06-03T06:20:40.271331Z",
          "shell.execute_reply": "2021-06-03T06:20:40.271909Z",
          "shell.execute_reply.started": "2021-06-03T06:05:26.349001Z"
        },
        "papermill": {
          "duration": 0.031416,
          "end_time": "2021-06-03T06:20:40.272072",
          "exception": false,
          "start_time": "2021-06-03T06:20:40.240656",
          "status": "completed"
        },
        "tags": [],
        "id": "innovative-ultimate"
      },
      "source": [
        "from tensorflow.keras.applications.vgg19 import preprocess_input as vgg_preprocess\n",
        "\n",
        "# tr_ds = _Dataset(X_train, y_train, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=vgg_preprocess)\n",
        "val_ds = _Dataset(X_val, y_val, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=vgg_preprocess)"
      ],
      "id": "innovative-ultimate",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:40.327849Z",
          "iopub.status.busy": "2021-06-03T06:20:40.326986Z",
          "iopub.status.idle": "2021-06-03T06:20:45.331984Z",
          "shell.execute_reply": "2021-06-03T06:20:45.332818Z",
          "shell.execute_reply.started": "2021-06-03T06:11:29.449033Z"
        },
        "papermill": {
          "duration": 5.038564,
          "end_time": "2021-06-03T06:20:45.333054",
          "exception": false,
          "start_time": "2021-06-03T06:20:40.294490",
          "status": "completed"
        },
        "tags": [],
        "id": "irish-afternoon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f5a279-adb4-467b-9ac1-24216ebab8bf"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers \n",
        "from PIL import Image\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "input_tensor = Input(shape=(112, 112, 3))\n",
        "base_model = VGG19(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers. GlobalAveragePooling2D())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(256, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(n_classes, activation = 'softmax'))\n",
        "model.summary()\n"
      ],
      "id": "irish-afternoon",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 3, 3, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 3, 3, 512)         2048      \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 20,158,274\n",
            "Trainable params: 20,157,250\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:45.404767Z",
          "iopub.status.busy": "2021-06-03T06:20:45.403204Z",
          "iopub.status.idle": "2021-06-03T06:20:45.411880Z",
          "shell.execute_reply": "2021-06-03T06:20:45.411302Z",
          "shell.execute_reply.started": "2021-06-02T14:49:35.248097Z"
        },
        "papermill": {
          "duration": 0.05092,
          "end_time": "2021-06-03T06:20:45.412027",
          "exception": false,
          "start_time": "2021-06-03T06:20:45.361107",
          "status": "completed"
        },
        "tags": [],
        "id": "integral-american",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511c771c-e0df-4b21-941f-49e850e045fc"
      },
      "source": [
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_path = \"COVIDMD.h5\"\n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n",
        "#ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, \n",
        "                                 save_best_only=True)\n"
      ],
      "id": "integral-american",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T06:20:45.474847Z",
          "iopub.status.busy": "2021-06-03T06:20:45.474073Z",
          "iopub.status.idle": "2021-06-03T07:07:06.819869Z",
          "shell.execute_reply": "2021-06-03T07:07:06.818885Z",
          "shell.execute_reply.started": "2021-06-02T14:51:01.39727Z"
        },
        "papermill": {
          "duration": 2781.379518,
          "end_time": "2021-06-03T07:07:06.820074",
          "exception": false,
          "start_time": "2021-06-03T06:20:45.440556",
          "status": "completed"
        },
        "tags": [],
        "id": "posted-gallery",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd0c8b1d-08f6-4ffe-ab5c-ec3a09c5b07c"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=100,\n",
        "                    validation_data=val_ds,\n",
        "                    validation_steps=int(np.ceil(X_val.shape[0]/BATCH_SIZE)), \n",
        "                    callbacks=[rlr_cb, checkpoint]\n",
        "#                     callbacks=[rlr_cb, ely_cb, checkpoint]\n",
        "                   )\n",
        "                   "
      ],
      "id": "posted-gallery",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "350/350 [==============================] - 65s 92ms/step - loss: 0.4336 - accuracy: 0.8039 - val_loss: 82.8728 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 82.87278, saving model to COVIDMD.h5\n",
            "Epoch 2/100\n",
            "350/350 [==============================] - 31s 87ms/step - loss: 0.2599 - accuracy: 0.8906 - val_loss: 31.3046 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00002: val_loss improved from 82.87278 to 31.30463, saving model to COVIDMD.h5\n",
            "Epoch 3/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.2067 - accuracy: 0.9140 - val_loss: 144.2349 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 31.30463\n",
            "Epoch 4/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.1818 - accuracy: 0.9240 - val_loss: 107.6144 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 31.30463\n",
            "Epoch 5/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.1583 - accuracy: 0.9385 - val_loss: 188.9611 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 31.30463\n",
            "Epoch 6/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.1400 - accuracy: 0.9455 - val_loss: 51.1018 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 31.30463\n",
            "Epoch 7/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.1175 - accuracy: 0.9576 - val_loss: 164.1434 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 31.30463\n",
            "Epoch 8/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0799 - accuracy: 0.9725 - val_loss: 254.1133 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 31.30463\n",
            "Epoch 9/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0616 - accuracy: 0.9771 - val_loss: 231.7126 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 31.30463\n",
            "Epoch 10/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0533 - accuracy: 0.9794 - val_loss: 188.3214 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 31.30463\n",
            "Epoch 11/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 133.2493 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 31.30463\n",
            "Epoch 12/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 183.7260 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 31.30463\n",
            "Epoch 13/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0237 - accuracy: 0.9943 - val_loss: 179.9397 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 31.30463\n",
            "Epoch 14/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0190 - accuracy: 0.9952 - val_loss: 165.4733 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 31.30463\n",
            "Epoch 15/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 179.1789 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 31.30463\n",
            "Epoch 16/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 176.2672 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 31.30463\n",
            "Epoch 17/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 181.6191 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 31.30463\n",
            "Epoch 18/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 177.0532 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 31.30463\n",
            "Epoch 19/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0187 - accuracy: 0.9948 - val_loss: 176.8007 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 31.30463\n",
            "Epoch 20/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0142 - accuracy: 0.9957 - val_loss: 180.9422 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 31.30463\n",
            "Epoch 21/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 177.5875 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 31.30463\n",
            "Epoch 22/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 174.2271 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 31.30463\n",
            "Epoch 23/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 175.6660 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 31.30463\n",
            "Epoch 24/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 177.6221 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 31.30463\n",
            "Epoch 25/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 177.4658 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 31.30463\n",
            "Epoch 26/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 175.2496 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 31.30463\n",
            "Epoch 27/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 171.4587 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 31.30463\n",
            "Epoch 28/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 170.5811 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 31.30463\n",
            "Epoch 29/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 173.1391 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 31.30463\n",
            "Epoch 30/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 174.0249 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 31.30463\n",
            "Epoch 31/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 173.2622 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 31.30463\n",
            "Epoch 32/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 172.3479 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 31.30463\n",
            "Epoch 33/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 175.9865 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 31.30463\n",
            "Epoch 34/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 171.9879 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 31.30463\n",
            "Epoch 35/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 173.2410 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 31.30463\n",
            "Epoch 36/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0084 - accuracy: 0.9987 - val_loss: 173.5502 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 31.30463\n",
            "Epoch 37/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 173.2807 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 31.30463\n",
            "Epoch 38/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 172.6185 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 31.30463\n",
            "Epoch 39/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 172.2343 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 31.30463\n",
            "Epoch 40/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 175.7021 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 31.30463\n",
            "Epoch 41/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 172.0323 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 31.30463\n",
            "Epoch 42/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0104 - accuracy: 0.9973 - val_loss: 172.0039 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.55999976772614e-10.\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 31.30463\n",
            "Epoch 43/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 173.3883 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 31.30463\n",
            "Epoch 44/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 173.4929 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 31.30463\n",
            "Epoch 45/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 172.8758 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 31.30463\n",
            "Epoch 46/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 171.7167 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 31.30463\n",
            "Epoch 47/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0113 - accuracy: 0.9977 - val_loss: 174.1748 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 5.119999424429978e-11.\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 31.30463\n",
            "Epoch 48/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 172.8483 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 31.30463\n",
            "Epoch 49/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 174.3835 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 31.30463\n",
            "Epoch 50/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 172.4018 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 31.30463\n",
            "Epoch 51/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0093 - accuracy: 0.9982 - val_loss: 171.0861 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 31.30463\n",
            "Epoch 52/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 171.4699 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1.0239999126415712e-11.\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 31.30463\n",
            "Epoch 53/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 172.3752 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 31.30463\n",
            "Epoch 54/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 171.8686 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 31.30463\n",
            "Epoch 55/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 173.6015 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 31.30463\n",
            "Epoch 56/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 173.0397 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 31.30463\n",
            "Epoch 57/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0153 - accuracy: 0.9962 - val_loss: 171.1275 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.0479997905886727e-12.\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 31.30463\n",
            "Epoch 58/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0107 - accuracy: 0.9970 - val_loss: 172.0136 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 31.30463\n",
            "Epoch 59/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 171.6245 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 31.30463\n",
            "Epoch 60/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 170.5976 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 31.30463\n",
            "Epoch 61/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 171.2903 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 31.30463\n",
            "Epoch 62/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 171.4211 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00062: ReduceLROnPlateau reducing learning rate to 4.0959995811773456e-13.\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 31.30463\n",
            "Epoch 63/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 172.2481 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 31.30463\n",
            "Epoch 64/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 172.3291 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 31.30463\n",
            "Epoch 65/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0129 - accuracy: 0.9970 - val_loss: 173.9437 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 31.30463\n",
            "Epoch 66/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0113 - accuracy: 0.9968 - val_loss: 173.3632 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 31.30463\n",
            "Epoch 67/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 173.2968 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00067: ReduceLROnPlateau reducing learning rate to 8.191999053934474e-14.\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 31.30463\n",
            "Epoch 68/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 170.5494 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 31.30463\n",
            "Epoch 69/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 174.3085 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 31.30463\n",
            "Epoch 70/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 173.0766 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 31.30463\n",
            "Epoch 71/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 174.6507 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 31.30463\n",
            "Epoch 72/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0154 - accuracy: 0.9968 - val_loss: 174.3465 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00072: ReduceLROnPlateau reducing learning rate to 1.638399837891949e-14.\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 31.30463\n",
            "Epoch 73/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0120 - accuracy: 0.9968 - val_loss: 173.3164 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 31.30463\n",
            "Epoch 74/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 171.9079 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 31.30463\n",
            "Epoch 75/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 173.2225 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 31.30463\n",
            "Epoch 76/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 172.9042 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 31.30463\n",
            "Epoch 77/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 174.9759 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.27679981130917e-15.\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 31.30463\n",
            "Epoch 78/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 173.2471 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 31.30463\n",
            "Epoch 79/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 172.0770 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 31.30463\n",
            "Epoch 80/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 171.6599 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 31.30463\n",
            "Epoch 81/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 172.4180 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 31.30463\n",
            "Epoch 82/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 173.8620 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00082: ReduceLROnPlateau reducing learning rate to 6.553599792024929e-16.\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 31.30463\n",
            "Epoch 83/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0213 - accuracy: 0.9950 - val_loss: 171.7099 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 31.30463\n",
            "Epoch 84/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0108 - accuracy: 0.9975 - val_loss: 172.0152 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 31.30463\n",
            "Epoch 85/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0129 - accuracy: 0.9968 - val_loss: 174.3394 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 31.30463\n",
            "Epoch 86/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 172.9063 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 31.30463\n",
            "Epoch 87/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0122 - accuracy: 0.9970 - val_loss: 174.8244 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00087: ReduceLROnPlateau reducing learning rate to 1.3107199584049857e-16.\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 31.30463\n",
            "Epoch 88/100\n",
            "350/350 [==============================] - 32s 90ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 172.9256 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 31.30463\n",
            "Epoch 89/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 176.3145 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 31.30463\n",
            "Epoch 90/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 175.7668 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 31.30463\n",
            "Epoch 91/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 175.1606 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 31.30463\n",
            "Epoch 92/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 172.0081 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00092: ReduceLROnPlateau reducing learning rate to 2.6214399168099714e-17.\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 31.30463\n",
            "Epoch 93/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 173.9524 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 31.30463\n",
            "Epoch 94/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 173.1530 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 31.30463\n",
            "Epoch 95/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 171.4365 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 31.30463\n",
            "Epoch 96/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0130 - accuracy: 0.9971 - val_loss: 173.5916 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 31.30463\n",
            "Epoch 97/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0117 - accuracy: 0.9975 - val_loss: 173.8027 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 5.2428798336199434e-18.\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 31.30463\n",
            "Epoch 98/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0159 - accuracy: 0.9946 - val_loss: 173.9726 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 31.30463\n",
            "Epoch 99/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 173.2964 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 31.30463\n",
            "Epoch 100/100\n",
            "350/350 [==============================] - 32s 91ms/step - loss: 0.0157 - accuracy: 0.9959 - val_loss: 171.1476 - val_accuracy: 0.3174\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 31.30463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T07:07:09.838525Z",
          "iopub.status.busy": "2021-06-03T07:07:09.837326Z",
          "iopub.status.idle": "2021-06-03T07:07:10.225247Z",
          "shell.execute_reply": "2021-06-03T07:07:10.225772Z",
          "shell.execute_reply.started": "2021-06-02T14:58:14.311769Z"
        },
        "papermill": {
          "duration": 2.075577,
          "end_time": "2021-06-03T07:07:10.225942",
          "exception": false,
          "start_time": "2021-06-03T07:07:08.150365",
          "status": "completed"
        },
        "tags": [],
        "id": "lesbian-guatemala",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "97ec96c1-c6d6-4fe7-d299-503e9ea06413"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'go', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "id": "lesbian-guatemala",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T07:07:12.956505Z",
          "iopub.status.busy": "2021-06-03T07:07:12.955210Z",
          "iopub.status.idle": "2021-06-03T07:07:45.657099Z",
          "shell.execute_reply": "2021-06-03T07:07:45.656116Z",
          "shell.execute_reply.started": "2021-06-02T14:59:46.361096Z"
        },
        "papermill": {
          "duration": 34.074298,
          "end_time": "2021-06-03T07:07:45.657326",
          "exception": false,
          "start_time": "2021-06-03T07:07:11.583028",
          "status": "completed"
        },
        "tags": [],
        "id": "demographic-location",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcdb995-f037-4886-a097-bd3686475bdc"
      },
      "source": [
        "\n",
        "print(\"정확도 : %.2f \" %(model.evaluate(X_test, y_test)[1]))"
      ],
      "id": "demographic-location",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 4s 70ms/step - loss: 0.0798 - accuracy: 0.9833\n",
            "정확도 : 0.98 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-06-03T07:07:48.334285Z",
          "iopub.status.busy": "2021-06-03T07:07:48.333569Z",
          "iopub.status.idle": "2021-06-03T07:07:50.255663Z",
          "shell.execute_reply": "2021-06-03T07:07:50.256174Z",
          "shell.execute_reply.started": "2021-06-03T05:46:34.279701Z"
        },
        "papermill": {
          "duration": 3.261602,
          "end_time": "2021-06-03T07:07:50.256389",
          "exception": false,
          "start_time": "2021-06-03T07:07:46.994787",
          "status": "completed"
        },
        "tags": [],
        "id": "collaborative-temperature",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b281bd-c447-48ea-ddb8-a927a18264cc"
      },
      "source": [
        "import os, re, glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "from numpy import argmax\n",
        "from keras.models import load_model\n",
        "\n",
        "image_dir = '/content/drive/MyDrive/Covid Model/test/COVID/'\n",
        "categories = ['COVID','Non-COVID']\n",
        "\n",
        "def Dataization(img_path):\n",
        "    image_w = 112\n",
        "    image_h = 112\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, None, fx=image_w/img.shape[1], fy=image_h/img.shape[0])\n",
        "    return (img/256)\n",
        " \n",
        "src = []\n",
        "name = []\n",
        "test = []\n",
        "\n",
        "for file in os.listdir(image_dir):\n",
        "    if (file.find('.png') is not -1):      \n",
        "        src.append(image_dir + file)\n",
        "        name.append(file)\n",
        "        test.append(Dataization(image_dir + file))\n",
        " \n",
        " \n",
        "test = np.array(test)\n",
        "model = load_model('/content/drive/MyDrive/Covid Model/COVIDMD (3).h5')\n",
        "predict = model.predict_classes(test)\n",
        " \n",
        "for i in range(len(test)):\n",
        "    print(name[i] + \" : , Predict : \"+ str(categories[predict[i]]))\n"
      ],
      "id": "collaborative-temperature",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "kjr-21-e24-p2-8.png : , Predict : COVID\n",
            "kjr-21-e25-p1-6.png : , Predict : Non-COVID\n",
            "kjr-21-e24-p3-16.png : , Predict : COVID\n",
            "kjr-21-e24-p5-29.png : , Predict : COVID\n",
            "kjr-21-e24-p5-31.png : , Predict : COVID\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}